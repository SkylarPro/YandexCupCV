# YandexCup
## Сomputer vision competition by Yandex 
### Task
"В этой задаче мы предлагаем вам обучить мультимодальную модель на парах [текст поискового запроса, релевантное запросу изображение], полученных сопоставлением наиболее релевантных изображений и пользовательских запросов по реальным кликовым данным. Отметим, что предлагаемый датасет сильно отличается от "Image Captioning" датасетов (таких как MS COCO) спецификой сбора данных: тексты представляют из себя не подписи к изображениям, а реальные поисковые запросы пользователей, что определяет специфику данных. 
В датасете представлено более 5 миллионов уникальных изображений и более 20 миллионов уникальных пар [текст, изображение]."
### Quality control
Обученная вами модель будет тестироваться на задаче zero-shot классификации изображений, то есть вам необходимо обучить модель, способную классифицировать изображения, имея в распоряжении лишь список с русскоязычными названиями классов.
### Data format
#### Train 
Исходные данные для обучения представлены в виде файла metadata.json (в формате json-lines) следующей структуры:
```sh
{"image": 1, "queries": ["запрос1", "запрос2", "запрос3"]}
{"image": 2, "queries": ["запрос1", "запрос2", "запрос3"]}
```
В отдельном файле images.json даны ссылки на исходные изображения:
```sh
{"image": 1, "url": "http://path.to/image1.jpg"}
{"image": 2, "url": "http://path.to/image2.jpg"}
```
### Eval
Данные, на которых замеряется качество zero-shot классификации, представляют из себя несколько датасетов с изображениями. Каждый датасет расположен в отдельной директории с содержимым вида:
```sh
├── classes.json
└── img
    ├── 01204c5c-bdcd-4535-b981-318d12d16b40.jpg
    ├── 0135b8ce-1f9e-485a-81a1-82c302d44128.jpg
    ├── 0168b6e5-530b-4fde-801a-56f5c2d0762c.jpg
    ├── 01975fb0-ab0c-4b67-b159-e704d52b7660.jpg
```
## Solutions
> В последние 12 дней из 30 присоединился к данному турниру 
> ниже расскажу о тех решениях, которые мне удалось воплотить
### Data
> Данных много пишем быстрый код ))

Изображения необходимо скачать => написан конвеер для многопоточного скачивания/ проверки на корректность скачанных данных / динамического сокращения csv файла с текстами при отсутствии соответствующих им изображений.
Текстовые данные нуждались в предобработке, а некоторые автоматически исключались так как были неинформативны. В итоге тренировочный датасет состоял из 500 тысяч пар изображений и текстовых описаний к ним. Был проведен статистический анализ текстов для этого написал соответствующие инструменты ```src/utils/```. 
Реализовал идею разбиения текстовых описаний изображений на кластера что позволило тренировать сетку на более интересных случаях чем "Волк" vs "Танк" (подробнее **в пункте Model - clastering**). У изображений было несколько описаний бралось среднее между embedings


### Model - I2T
За время соревнований попробовал следующие модели для задачи I2T:
- CLIP by Sber на text_features стоит GPT3small (прошла по весу, ее принял за baseline)
- CLIP by Sber на text_features стоит GPT3small + cls_Layer => N layers projections (кастомная версия модели выше). Суть в том, что на выходе модель для каждого кластера имеет свой linear_projection т.е. параллельно GPT3small работает быстрая сетка на 1 трансформере и линейном слое, которая предсказывает номер кластера данного предложения и в зависимости от этого определяет его layers projections. Такая штука поможет лучше различать более сложные  ситуации внутри кластера, нежели тренировка одного projections для всех данных. Все эта система тренируется  End-to-End (backpropagation).
- CLIP by OpenAI (работал из коробки)
- CLIP by OpenAI на text_features поставил RuBERT (модель не влезла в ограничения по весу)
- CLIP на text_features BPE (предоставили организаторы) + 4 transformer block (оставил за кадром)
### Clastering Pipline
1. В ходе текстового анализа были выбраны оптимальный размер n-gram n = 3  
2. Обучен BoW и с него взяты первые 20.000 3-gram
3. С помощью SentenceTransformer by Sber (предназначена для выявления семантических свойств в предложениях) получены embedings для 20.000 текстов
4. На полученных в пункте 3 embedings обучен алгоритм кластеризации AgglomerativeClustering 
5. Далее по данным кластеризации обучен алгоритм KNeighborsClassifier
##### Inference Clastering 
* SentenceTransformer -> KNeighborsClassifier
### Train
> На тренировку оставалось 4 дня, что очень мало для задач данного рода, но основная идея была следующей.

BaseLine на inference давал accuracy в 42%. На всех тренировках был заморожен visual_encoder, кроме его последнего слоя projection_layer. Далее опишу этапы обучения text_encoder.
1. Тренируем последний три трансформера в GPT3small. За 7 эпох дало буст до 48%.
![alt text](https://psv4.userapi.com/c520036/u137937464/docs/d19/910453ea5279/Snimok_ekrana_2021-11-15_v_12_04_00.png?extra=WwoLm11A5scJgbCcNf6F9NArb9It3uj_wVNT7069EqTmsM2Hs1wayYb_RlJpXYNDwq7Y-8KjDysjRHgEZTJrwF6YAl3bx7iVRq23vrwywrJgwvDR6gH7Kczj-Z9ykJZALIX-63uD0cTgVCrh00arqOAfHWc)
2. Тренируем последний три трансформера в GPT3small + embedings. За 14 эпох дало буст до 56%.
![alt text](https://psv4.userapi.com/c536132/u137937464/docs/d19/b2430a6483b7/Snimok_ekrana_2021-11-15_v_12_08_46.png?extra=CKMlfnpyptn_ICIqJ3HJ4UKee-rC0X5vW8rZWIR9_XBnoWjlyubo-gj4c3jrGn7iwu-UeBt-YPAmUF3Uon3Y0V2a82V2UtyD34hqVLfHP58KRusktov_3_k8nzan_gKWveeScUrCnVxEdEPU1TVbCBB2z_E)
3. Тренировку внутри кластера, к сожалению не успел сделать на турнире. 
4. Тренировку кастомной модели c множеством projections, к сожалению не успел сделать на турнире.

Много временя занял подбор гиппермараметров, пришел к тому, что оптимальный batch_size >= 256, lr <= 1e-04, wd >= 5e-05, scheduler - cosine annealing, использовал optimizer Adam, так как не было времени настраивать SGD. Text preprocessing/image augmentation можно посмотреть в  ``` inference/```. Обучение одной эпохи заняло 3 часа на 2080 TI.

## Results
Сделан pipline (simple MLOps решение):
1. Автоматическое многопоточное скачивания данных.
2. Обработки данных, разбиения их на кластеры.
3. Обучения моделей i2t, создание моделей кластеризации и их применение.
4. Оценка качества моделей, логирование.
5. Работа на inference моделей.

## Sources of information

-  [CLIP by OpenAI](https://arxiv.org/abs/2103.00020)
- [CLIP by Sber](https://github.com/sberbank-ai/ru-clip)
- [SentenceTransformers](https://www.sbert.net)
- [Model GPT2small](https://arxiv.org/abs/2005.14165)
- [Model VIT-B32](https://arxiv.org/pdf/2010.11929.pdf)
- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)
- [Faiss (speed models by Meta)](https://github.com/facebookresearch/faiss)

## In developing 
1. Создать автоматическую сборку моделей по конфигу
2. Настроить пути импортов


**by SkylarPro**
## License
MIT
