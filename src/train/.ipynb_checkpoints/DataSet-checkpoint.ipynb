{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "equal-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "\n",
    "import multiprocessing  as mp\n",
    "import requests\n",
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "center-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/data/hdd1/brain/BraTS19/YandexCup/ru-clip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "appreciated-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clip.evaluate.utils import (\n",
    "    get_text_batch, get_image_batch, get_tokenizer,\n",
    "    show_test_images, show_similarity,\n",
    "    prepare_classes, call_model,\n",
    "    show_topk_probs,\n",
    "    load_weights_only,\n",
    "    get_topk_accuracy,\n",
    "    show_topk_accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "civilian-gates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 2, 3, 4, 8, 9, 11, 12, 14, 15, 18, 19}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в csv file для каждого касса должен быть массив\n",
    "model, args = load_weights_only(\"ViT-B/32-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "refined-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sent2textDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,path_t_csv, path_i_json, \n",
    "                 path_i_folder, down_data = False,\n",
    "                 n_classes = 20, args = None,\n",
    "                 tokenizer = None, clastering_mode = False,\n",
    "                 transform = None, mode = \"Sber\",\n",
    "                ):\n",
    "        \"\"\"\n",
    "        path_t_csv - путь до csv файла с текстами\n",
    "        path_i_json - путь до json файла с картинками\n",
    "        path_i_folder - путь для сохранения скаченных фотографий\n",
    "        clastering_mode - тексты разбиты на кластеры\n",
    "        \"\"\"\n",
    "        self.text_data = path_t_csv #pd.read_csv(path_t_csv)\n",
    "        self.img_name_to_text = None # change in self._load_json_links() ускоряет поиск по файлам\n",
    "        self.img_links = self._load_json_links(path_i_json) # only in text_data\n",
    "        \n",
    "        \n",
    "        self.path_to_img = path_i_folder if path_i_folder else path_i_json\n",
    "        \n",
    "        if down_data:\n",
    "            manager = mp.Manager()\n",
    "            self._imgs_path = manager.Queue()\n",
    "            self._load_imgs(list(self.img_links.items()),n_workers = 16)\n",
    "        else:\n",
    "            #check data\n",
    "            self._check_data_in_folder(path_i_folder)\n",
    "            \n",
    "        self.clastering_mode = clastering_mode\n",
    "        self.transform = transform\n",
    "        self.args = args\n",
    "        self.mode = mode\n",
    "        self.n_classes = n_classes\n",
    "        self.tokenizer = get_tokenizer() if tokenizer == None else tokenizer\n",
    "        \n",
    "        \n",
    "    def __len__(self,):\n",
    "        return self.text_data.id_img.unique().shape[0]\n",
    "    \n",
    "    \n",
    "    def _stack_texts(self,now_idx):\n",
    "        if self.clastering_mode:\n",
    "            pass\n",
    "        else:\n",
    "            indexs = [random.randint(0,len(self.text_data)-1) for i in range(self.n_classes-1)]\n",
    "            #проверка на совпадение индексов\n",
    "            for i in range(len(indexs)):\n",
    "                if indexs[i] == now_idx:\n",
    "                    indexs[i] = now_idx + 1\n",
    "                    \n",
    "            texts = [self.text_data.iloc[idx][0] for idx in indexs]\n",
    "            return texts\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        code = self.text_data.iloc[idx,1]\n",
    "        name_img = self.img_links.get(code)[0]\n",
    "        \n",
    "        img = cv2.imread(f\"{self.path_to_img}/{name_img}.jpg\", cv2.IMREAD_COLOR)\n",
    "        \n",
    "        text = self.text_data.iloc[idx][0] # get gt text\n",
    "        \n",
    "        texts = self._stack_texts(idx) # create new class\n",
    "        texts.append(text)\n",
    "        #add shuffle \n",
    "        labels = torch.tensor([0 if i != self.n_classes - 1 else 1\n",
    "                               for i in range(self.n_classes)], \n",
    "                              dtype=torch.int32)\n",
    "        \n",
    "        if self.mode == \"Sber\":\n",
    "            assert self.args != None, f\"Define args\"\n",
    "            input_ids, attention_mask = get_text_batch(texts, self.tokenizer, self.args)\n",
    "            if self.transform == None:\n",
    "                image = [Image.fromarray(img)] # corret this line\n",
    "                img_input = get_image_batch(image, self.args.img_transform, self.args)\n",
    "            else:\n",
    "                img_input = self.transform(img)\n",
    "                \n",
    "        return (img_input, input_ids, attention_mask), labels\n",
    "        \n",
    "        \n",
    "    \n",
    "    def _check_data_in_folder(self,path_i_folder):\n",
    "        #оставить в csv файле только те sample изображения которых есть в папке\n",
    "        onlyfiles = [f for f in listdir(path_i_folder) if isfile(join(path_i_folder, f))]\n",
    "        counter = 0\n",
    "        start_count = len(self.text_data.id_img.unique())\n",
    "        for id_img in self.text_data.id_img.unique().copy():\n",
    "            if self.img_name_to_text.get(id_img) == None:\n",
    "                self.text_data = self.text_data.drop(self.text_data[self.text_data.id_img == id_img].index)\n",
    "            else:\n",
    "                counter+= 1\n",
    "        print(f\"From {start_count} sample folder hasn't {start_count - counter}\")\n",
    "                \n",
    "    \n",
    "    def _load_json_links(self,data_path: str, only_i_from_csv = True)->Dict[int, Tuple[str,str]]:\n",
    "        data = []\n",
    "        only_csv_links = []\n",
    "        with jsonlines.open(data_path) as reader:\n",
    "            reader = tqdm(reader)\n",
    "            for obj in reader:\n",
    "                data.append((obj['image'], obj['url']))\n",
    "                \n",
    "        if only_i_from_csv:\n",
    "            #скачивать изображения принадлежащие csv\n",
    "            only_csv_links = {idx: data[idx] for idx in self.text_data.id_img.unique()}\n",
    "            self.img_name_to_text = {idx: data[idx][0] for idx in self.text_data.id_img.unique()}\n",
    "            return only_csv_links\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def _worker(self,task):\n",
    "        paths_img = self._load_img(task)\n",
    "        self._imgs_path.put(paths_img)\n",
    "        \n",
    "    \n",
    "    def _load_img(self,links: Tuple[int,Tuple[str,str]])->int:\n",
    "        try:\n",
    "            response = requests.get(f\"{links[1][1]}\")\n",
    "            with open(f\"{self.path_to_img}/{links[1][0]}.jpg\", \"wb\") as img:\n",
    "                img.write(response.content)\n",
    "            return links[0]\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            print(f\"Oyy, miss {links[0]}\")\n",
    "            \n",
    "    def _load_imgs(self, links: List[Tuple[int, Tuple[str,str]]], n_workers = 1)->bool:\n",
    "        all_row = set(self.text_data.id_img.unique())\n",
    "        return_row = set()\n",
    "        all_len = len(all_row)\n",
    "        print(links)\n",
    "        with mp.Pool(n_workers) as p:\n",
    "            p.map(self._worker, links)\n",
    "            \n",
    "            for _ in range(len(links)):\n",
    "                return_row.add(self._imgs_path.get())\n",
    "                \n",
    "        all_row.difference_update(return_row)\n",
    "        \n",
    "        for row in all_row:\n",
    "             self.text_data = self.text_data.drop(self.text_data[self.text_data.id_img == row].index)\n",
    "        \n",
    "        assert all_len - len(all_row) == len(self.text_data.id_img.unique())\n",
    "        \n",
    "        print(f\"Download photo {all_len - len(all_row)} with {all_len} finish\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "proprietary-vintage",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5462418it [00:12, 451216.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 352 sample folder hasn't 0\n"
     ]
    }
   ],
   "source": [
    "path_t_csv_no_clastr = pd.read_csv(\"data/preproc_text700.csv\")[1000:2000] #\"data/preproc_text700.csv\"\n",
    "path_i_json = \"data/images.json\"\n",
    "path_i_folder = \"data/images\"\n",
    "\n",
    "ds = Sent2textDataset(path_t_csv_no_clastr, path_i_json, path_i_folder,args = args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "capital-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "neither-feature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "freelance-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf  data/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "certain-specification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.json  metadata.json  preproc_text700.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/\n",
    "!mkdir data/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "weird-survey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000     941193\n",
       "1001     941193\n",
       "1002     941193\n",
       "1003    1370697\n",
       "1004    1370697\n",
       "         ...   \n",
       "1995    4731110\n",
       "1996    4731110\n",
       "1997    4731110\n",
       "1998    1444968\n",
       "1999    1444968\n",
       "Name: id_img, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_t_csv_no_clastr.id_img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-writer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
