{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sent2textDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,path_t_csv, path_i_json, \n",
    "                 path_i_folder, down_data = False,\n",
    "                 n_classes = 20, args = None,\n",
    "                 tokenizer = None, clastering_mode = False,\n",
    "                 transform = None, mode = \"Sber\",\n",
    "                ):\n",
    "        \"\"\"\n",
    "        path_t_csv - путь до csv файла с текстами\n",
    "        path_i_json - путь до json файла с картинками\n",
    "        path_i_folder - путь для сохранения скаченных фотографий\n",
    "        clastering_mode - тексты разбиты на кластеры\n",
    "        \"\"\"\n",
    "        self.text_data = pd.read_csv(path_t_csv)\n",
    "        self.img_links = self._load_json_links(path_i_json) # links to download images\n",
    "        \n",
    "        \n",
    "        self.path_to_img = path_i_folder if path_i_folder else path_i_json\n",
    "        \n",
    "        if down_data:\n",
    "            manager = mp.Manager()\n",
    "            self._imgs_path = manager.Queue()\n",
    "            self._load_imgs(list(self.img_links.items()),n_workers = 16)\n",
    "        else:\n",
    "            #check data\n",
    "            self._check_data_in_folder()\n",
    "            \n",
    "        self.clastering_mode = clastering_mode\n",
    "        self.transform = transform\n",
    "        self.args = args\n",
    "        self.mode = mode\n",
    "        # class count get for traning\n",
    "        self.n_classes = n_classes\n",
    "        # for tokenizer text, depend on model\n",
    "        self.tokenizer = get_tokenizer() if tokenizer == None else tokenizer\n",
    "        \n",
    "        \n",
    "    def __len__(self,):\n",
    "        return self.text_data.id_img.unique().shape[0]\n",
    "    \n",
    "    \n",
    "    def _stack_texts(self,now_idx):\n",
    "        \"\"\"\n",
    "        return text.shape(1, self.n)\n",
    "        \"\"\"\n",
    "        # get text with differend class or with currently class\n",
    "        if self.clastering_mode:\n",
    "            pass\n",
    "        else:\n",
    "            indexs = [random.randint(0,len(self.text_data)-1) for i in range(self.n_classes-1)]\n",
    "            #проверка на совпадение индексов\n",
    "            for i in range(len(indexs)):\n",
    "                if indexs[i] == now_idx:\n",
    "                    indexs[i] = now_idx + 1\n",
    "            \n",
    "            texts = []\n",
    "            for i in indexs:\n",
    "                t = self.text_data.iloc[i][0].split(\"SEP\")[1:]\n",
    "                t = t[random.randint(0,len(t)-1)]\n",
    "                texts.append(t)\n",
    "                \n",
    "            return texts \n",
    "    \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        name_img = self.text_data.iloc[idx,1]\n",
    "                \n",
    "        img = cv2.imread(f\"{self.path_to_img}/{name_img}.jpg\", cv2.IMREAD_COLOR)\n",
    "        text = self.text_data.iloc[idx][0].split(\"SEP\")[1:] # get gt text\n",
    "        \n",
    "        #get one random text\n",
    "        txt_idx = random.randint(0,len(text)-1)\n",
    "        text = text[txt_idx]\n",
    "        \n",
    "        texts = self._stack_texts(idx) # create new class\n",
    "        \n",
    "        gt_idx = random.randint(0,self.n_classes - 1)\n",
    "        texts.insert(gt_idx, text)\n",
    "        \n",
    "        \n",
    "        if self.mode == \"Sber\":\n",
    "            assert self.args != None, f\"Define args\"\n",
    "            input_ids, attention_mask = get_text_batch(texts, self.tokenizer, self.args)\n",
    "            if self.transform == None:\n",
    "                image = [Image.fromarray(img)] # get_image_batch take shape count_i,img_dat\n",
    "                img_input = get_image_batch(image, self.args.img_transform, self.args)\n",
    "            else:\n",
    "                img_input = self.transform(img)\n",
    "                \n",
    "        return (img_input, input_ids, attention_mask), gt_idx, texts\n",
    "        \n",
    "        \n",
    "    \n",
    "    def _check_data_in_folder(self,):\n",
    "        \"\"\"\n",
    "        Delete rows with csv file which no in folder.\n",
    "        \"\"\"\n",
    "        #оставить в csv файле только те sample изображения которых есть в папке\n",
    "        print(self.path_to_img)\n",
    "        onlyfiles = {int(f[:-4]): True for f in listdir(self.path_to_img) if isfile(join(self.path_to_img, f))}\n",
    "        counter = 0\n",
    "        start_count = len(self.text_data.id_img.unique())\n",
    "        for id_img in self.text_data.id_img.unique().copy():\n",
    "            if onlyfiles.get(id_img) == None:\n",
    "                self.text_data = self.text_data.drop(self.text_data[self.text_data.id_img == id_img].index)\n",
    "            else:\n",
    "                counter+= 1\n",
    "        print(f\"From {start_count} sample folder hasn't {start_count - counter}\")\n",
    "                \n",
    "    \n",
    "    def _load_json_links(self,data_path: str, only_i_from_csv = True)->Dict[int, Tuple[str,str]]:\n",
    "        \"\"\"\n",
    "        load data with json to variable\n",
    "        \"\"\"\n",
    "        data = {}\n",
    "        only_csv_links = []\n",
    "        with jsonlines.open(data_path) as reader:\n",
    "            reader = tqdm(reader)\n",
    "            for obj in reader:\n",
    "                if obj['image'] not in data:\n",
    "                    data[obj['image']] = obj['url']\n",
    "                \n",
    "        if only_i_from_csv:\n",
    "            #скачивать изображения принадлежащие csv\n",
    "            only_csv_links = {idx: data[idx] for idx in self.text_data.id_img.unique()}\n",
    "            return only_csv_links\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def _worker(self,task):\n",
    "        paths_img = self._load_img(task)\n",
    "        self._imgs_path.put(paths_img)\n",
    "        \n",
    "    \n",
    "    def _load_img(self,links: Tuple[int,str])->int:\n",
    "        try:\n",
    "            response = requests.get(f\"{links[1]}\")\n",
    "            with open(f\"{self.path_to_img}/{links[0]}.jpg\", \"wb\") as img:\n",
    "                if response.content:\n",
    "                    img.write(response.content)\n",
    "                    return links[0]\n",
    "                else:\n",
    "                    print(f\"Oyy response empty, miss {links[0]}\")\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            print(f\"Oyy, miss {links[0]}\")\n",
    "            \n",
    "    def _load_imgs(self, links:  List[Tuple[int,str]], n_workers = 1) -> bool:\n",
    "        \"\"\"\n",
    "        download imgs from network\n",
    "        \"\"\"\n",
    "        all_row = set(self.text_data.id_img.unique())\n",
    "        return_row = set()\n",
    "        all_len = len(all_row)\n",
    "        with mp.Pool(n_workers) as p:\n",
    "            p.map(self._worker, links)\n",
    "            \n",
    "            for _ in range(len(links)):\n",
    "                return_row.add(self._imgs_path.get())\n",
    "                \n",
    "        all_row.difference_update(return_row)\n",
    "        \n",
    "        for row in all_row:\n",
    "             self.text_data = self.text_data.drop(self.text_data[self.text_data.id_img == row].index)\n",
    "        \n",
    "        assert all_len - len(all_row) == len(self.text_data.id_img.unique())\n",
    "        \n",
    "        print(f\"Download photo {all_len - len(all_row)} with {all_len} finish\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-drawing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
